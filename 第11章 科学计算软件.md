# 第11章 科学计算软件

> HPC环境下的科学计算软件部署、管理和优化

## 11.1 常用科学计算软件安装

### 11.1.1 数值计算软件

#### MATLAB/Octave：数值计算和数据分析

**安装配置和许可证管理：**

```bash
# MATLAB安装示例
tar -xzf matlab_R2023a_glnxa64.tar.gz
cd matlab_R2023a_glnxa64
sudo ./install -mode silent -inputFile installer_input.txt

# installer_input.txt配置示例
destinationFolder=/opt/matlab/R2023a
fileInstallationKey=XXXXX-XXXXX-XXXXX-XXXXX-XXXXX-XXXXX
agreeToLicense=yes
outputFolder=/tmp/matlab_install
mode=silent
```

**并行计算工具箱配置：**

```matlab
% 并行池配置
parpool('local', 32);  % 创建32个工作进程的并行池

% 分布式计算配置
cluster = parcluster('MyCluster');
parpool(cluster, 64);

% GPU计算配置
gpuDevice;  % 检查GPU设备
```

#### Python科学计算栈

**基础环境安装：**

```bash
# Miniconda安装
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda3

# 科学计算包安装
conda install numpy scipy pandas matplotlib seaborn jupyter

# 并行计算包
conda install joblib dask ipyparallel
```

**Jupyter Notebook集群配置：**

```python
# jupyter_notebook_config.py配置
c = get_config()

# 允许远程访问
c.NotebookApp.ip = '0.0.0.0'
c.NotebookApp.open_browser = False
c.NotebookApp.port = 8888

# 密码认证
c.NotebookApp.password_required = True
c.NotebookApp.password = 'sha1:xxx:xxx'

# SSL配置
c.NotebookApp.certfile = '/path/to/your/certificate.pem'
c.NotebookApp.keyfile = '/path/to/your/privatekey.pem'
```

#### R语言：统计分析和数据科学

**CRAN包管理：**

```r
# 安装常用包
install.packages(c("tidyverse", "data.table", "caret", "randomForest"))

# 并行计算包
install.packages(c("parallel", "foreach", "doParallel"))

# 高性能计算扩展
install.packages(c("Rmpi", "snow", "future"))
```

**并行计算配置：**

```r
# 使用parallel包
library(parallel)
cl <- makeCluster(detectCores() - 1)
clusterEvalQ(cl, library(data.table))
result <- parLapply(cl, data_list, function(x) { process_data(x) })
stopCluster(cl)

# 使用foreach包
library(doParallel)
cl <- makeCluster(32)
registerDoParallel(cl)
result <- foreach(i = 1:100, .combine = rbind) %dopar% {
    compute_task(i)
}
stopImplicitCluster()
```

### 11.1.2 工程仿真软件

#### ANSYS：有限元分析套件

**Fluent安装配置：**

```bash
# 解压安装包
tar -xzf ANSYS_Products_2023R1_LINX64.tgz
cd ANSYS_Products_2023R1_LINX64

# 静默安装配置
./INSTALL -silent -install_dir /opt/ansys_inc/v231 \
    -ansysedt_dir /opt/ansys_inc/v231/ansysedt \
    -license_server 2325@license-server

# 许可证服务器配置
export ANSYSLMD_LICENSE_FILE=2325@license-server
export LM_LICENSE_FILE=2325@license-server
```

**并行求解器设置：**

```bash
# Fluent并行计算
fluent 3d -t32 -cnf=nodes.list -g < input.jou

# Workbench并行配置
# 在Workbench中设置：
# Tools > Options > Parallel Processing > Enable Parallel Processing
# 设置进程数和节点配置
```

#### COMSOL Multiphysics：多物理场仿真

**模块化安装配置：**

```bash
# COMSOL安装
tar -xzf comsol56_linux_x86_64.tar.gz
cd comsol56
sudo ./install.sh

# 许可证服务器配置
export COMSOL_LICENSE_FILE=27000@license-server
```

**并行求解器配置：**

```bash
# 命令行并行启动
comsol batch -inputfile model.mph -outputfile result.mph \
    -mpibootstrap slurm -np 64

# 在COMSOL GUI中配置：
# Study > Solver Configurations > Parametric Sweep > Parametric Solver
# 设置并行参数
```

### 11.1.3 分子模拟软件

#### GROMACS：分子动力学模拟

**CPU/GPU加速配置：**

```bash
# CPU版本编译
cmake .. -DCMAKE_INSTALL_PREFIX=/opt/gromacs/2023 \
    -DGMX_BUILD_OWN_FFTW=ON \
    -DGMX_MPI=ON \
    -DGMX_OPENMP=ON \
    -DCMAKE_C_COMPILER=gcc \
    -DCMAKE_CXX_COMPILER=g++

make -j$(nproc)
make install

# GPU版本编译
cmake .. -DCMAKE_INSTALL_PREFIX=/opt/gromacs/2023-gpu \
    -DGMX_BUILD_OWN_FFTW=ON \
    -DGMX_MPI=ON \
    -DGMX_OPENMP=ON \
    -DGMX_GPU=CUDA \
    -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda
```

**并行MPI编译：**

```bash
# 使用Intel MPI编译
module load intel/2023
module load impi/2023

cmake .. -DCMAKE_INSTALL_PREFIX=/opt/gromacs/2023-impi \
    -DCMAKE_C_COMPILER=mpiicc \
    -DCMAKE_CXX_COMPILER=mpiicpc \
    -DGMX_MPI=ON \
    -DGMX_OPENMP=ON
```

**性能调优参数：**

```bash
# mdrun调用示例
mpirun -np 64 gmx_mpi mdrun -s topol.tpr -ntomp 4 -gpu_id 0123 \
    -pin on -pinoffset 0 -pinstride 1 \
    -dlb yes -rdd 1.2 -rcon 1.4

# 关键参数说明：
# -ntomp: 每个MPI进程的OpenMP线程数
# -gpu_id: GPU设备ID分配
# -pin: 进程绑定
# -dlb: 动态负载平衡
# -rdd: 网格间距
```

#### NAMD：大规模分子动力学

**多核并行优化：**

```bash
# NAMD编译配置
./config Linux-x86_64-g++ --charm-arch mpi-linux-x86_64 \
    --with-tcl --with-tcllib --with-tclinc

make -j$(nproc)

# 并行运行配置
charmrun +p64 namd2 +setcpuaffinity config.conf \
    +ppn 8 +commap mapfile
```

**GPU加速配置：**

```bash
# CUDA版本编译
./config Linux-x86_64-CUDA --charm-arch mpi-linux-x86_64-cuda \
    --with-cuda --cuda-prefix=/usr/local/cuda

# GPU运行配置
charmrun +p64 namd2 +setcpuaffinity +devices 0,1,2,3 config.conf
```

### 11.1.4 计算化学软件

#### Gaussian：量子化学计算

**许可证管理：**

```bash
# Gaussian安装
tar -xzf g16.tgz
cd g16
sudo ./install

# 许可证文件配置
export g16root=/opt/gaussian
export GAUSS_EXEDIR=$g16root/g16
export GAUSS_ARCHDIR=$g16root/g16
export GAUSS_BSDDIR=$g16root/basis
export GAUSS_LEXEDIR=$g16root/local

# 许可证服务器
export GAUSS_LFLAGS="-license /opt/gaussian/g16/license.dat"
```

**并行版本配置：**

```bash
# 并行计算配置
export GAUSS_PFLAGS="-p$GAUSS_PARALLEL"

# 输入文件示例
%NProcShared=32
%Mem=64GB
#P B3LYP/6-31G(d) Opt Freq

# 并行运行
g16 job.com job.log
```

#### VASP：材料模拟

**MPI并行编译：**

```bash
# VASP编译配置
cd vasp.6.3.2
cp arch/makefile.include.linux_intel makefile.include

# 修改makefile.include
CPP_OPTIONS= -DMPI -DHOST=\"LinuxIFC\" -DIFC \
             -DCACHE_SIZE=4000 -DPGF90 -DNGZhalf \
             -Dkind8 -DMPI_BLOCK=8000 -Duse_collective \
             -DscaLAPACK -Duse_bse_te \
             -Dtbdyn -Duse_shmem -D_OPENMP

FC=mpiifort
CC=mpiicc
SCALAPACK=-mkl=cluster

make std gam ncl
```

**GPU加速版本：**

```bash
# GPU版本编译
cd vasp.6.3.2
cp arch/makefile.include.linux_intel_cuda makefile.include

# 修改makefile.include
CPP_OPTIONS= -DMPI -DHOST=\"LinuxIFC\" -DIFC \
             -DCACHE_SIZE=4000 -DPGF90 -DNGZhalf \
             -Dkind8 -DMPI_BLOCK=8000 -Duse_collective \
             -DscaLAPACK -Duse_bse_te -Dtbdyn -Duse_shmem \
             -D_OPENMP -DCUDA

CUDA=cuda_11.8.0
CUDA_ROOT=/usr/local/$CUDA
NVCC=$CUDA_ROOT/bin/nvcc
NVCC_LIB=$CUDA_ROOT/lib64/stubs

make gpu
```

### 11.1.5 计算流体力学软件

#### OpenFOAM：开源CFD软件

**源码编译配置：**

```bash
# OpenFOAM依赖安装
sudo apt-get install build-essential flex bison cmake zlib1g-dev \
    qt5-default libqt5webkit5-dev libqt5x11extras5-dev \
    libqt5x11extras5-dev libqt5opengl5-dev libqt5x11extras5 \
    libboost-system-dev libboost-thread-dev libboost-date-time-dev \
    libboost-filesystem-dev libboost-program-options-dev \
    libboost-iostreams-dev libscotch-dev libptscotch-dev

# 下载源码
git clone https://github.com/OpenFOAM/OpenFOAM-11.x.git
git clone https://github.com/OpenFOAM/ThirdParty-11.x.git

# 编译配置
cd OpenFOAM-11.x
./Allwmake -j$(nproc)
```

**并行计算设置：**

```bash
# decomposePar配置
# system/decomposeParDict
numberOfSubdomains 64;
method          scotch;

# 运行并行计算
decomposePar
mpirun -np 64 interFoam -parallel
reconstructPar
```

**自定义求解器开发：**

```cpp
// 自定义求解器示例
#include "fvCFD.H"
#include "pimpleControl.H"

int main(int argc, char *argv[])
{
    #include "setRootCaseLists.H"
    #include "createTime.H"
    #include "createMesh.H"
    #include "createFields.H"
    #include "createFvOptions.H"

    pimpleControl pimple(mesh);

    while (runTime.loop())
    {
        #include "CourantNo.H"

        // 求解器逻辑
        while (pimple.loop())
        {
            solve(fvm::ddt(U) + fvm::div(phi, U) == ...);
        }

        runTime.write();
    }

    return 0;
}
```

## 11.2 容器化部署（Docker、Singularity）

### 11.2.1 Docker容器技术

#### Docker基础概念

**Dockerfile编写示例：**

```dockerfile
# 科学计算基础镜像
FROM ubuntu:22.04

# 系统更新和基础包安装
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    wget \
    curl \
    git \
    python3 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# 安装Python科学计算栈
RUN pip3 install --no-cache-dir \
    numpy \
    scipy \
    pandas \
    matplotlib \
    jupyter \
    scikit-learn \
    tensorflow \
    pytorch

# 设置工作目录
WORKDIR /workspace

# 暴露端口
EXPOSE 8888

# 启动命令
CMD ["jupyter", "notebook", "--ip=0.0.0.0", "--no-browser", "--allow-root"]
```

**多阶段构建优化：**

```dockerfile
# 构建阶段
FROM ubuntu:22.04 as builder

RUN apt-get update && apt-get install -y \
    build-essential cmake wget

WORKDIR /build

# 下载和编译GROMACS
RUN wget ftp://ftp.gromacs.org/pub/gromacs/gromacs-2023.tar.gz && \
    tar -xzf gromacs-2023.tar.gz && \
    cd gromacs-2023 && \
    mkdir build && cd build && \
    cmake .. -DCMAKE_INSTALL_PREFIX=/opt/gromacs \
             -DGMX_BUILD_OWN_FFTW=ON \
             -DGMX_MPI=ON && \
    make -j$(nproc) && \
    make install

# 运行阶段
FROM ubuntu:22.04

# 复制编译好的二进制文件
COPY --from=builder /opt/gromacs /opt/gromacs

# 安装运行时依赖
RUN apt-get update && apt-get install -y \
    libopenmpi3 \
    openmpi-bin \
    && rm -rf /var/lib/apt/lists/*

ENV PATH="/opt/gromacs/bin:${PATH}"

WORKDIR /workspace
CMD ["bash"]
```

#### Docker性能优化

**镜像大小优化：**

```dockerfile
# 使用多阶段构建
FROM ubuntu:22.04 as builder
# ... 编译步骤 ...

FROM ubuntu:22.04
# 只复制必要的文件
COPY --from=builder /path/to/binary /usr/local/bin/
# 清理不必要的文件
RUN apt-get clean && rm -rf /var/lib/apt/lists/*
```

**资源限制配置：**

```bash
# Docker运行时资源限制
docker run -it --rm \
    --cpus="8" \
    --memory="16g" \
    --memory-swap="16g" \
    --shm-size="2g" \
    --pid="host" \
    --userns="host" \
    scientific-image:latest

# GPU支持
docker run --gpus all -it scientific-image:latest
```

### 11.2.2 Singularity容器

#### Singularity特点

**Singularity定义文件：**

```singularity
Bootstrap: docker
From: ubuntu:22.04

%post
    # 系统更新
    apt-get update && apt-get install -y \
        build-essential \
        cmake \
        python3 \
        python3-pip

    # 安装科学计算包
    pip3 install numpy scipy pandas matplotlib

    # 清理
    apt-get clean
    rm -rf /var/lib/apt/lists/*

%environment
    export PATH="/opt/conda/bin:$PATH"
    export PYTHONPATH="/opt/conda/lib/python3.10/site-packages:$PYTHONPATH"

%runscript
    exec python3 "$@"

%files
    ./data /opt/data
    ./scripts /opt/scripts

%labels
    Author HPCAdmin
    Version 1.0
    Description "Scientific computing container"
```

#### HPC环境部署

**与SLURM集成：**

```bash
# SLURM作业脚本
#!/bin/bash
#SBATCH --job-name=singularity_test
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=32
#SBATCH --time=01:00:00

# 加载Singularity模块
module load singularity

# 运行容器
srun singularity exec scientific.sif mpirun python3 mpi_script.py

# GPU支持
srun singularity exec --nv scientific.sif nvidia-smi
```

**GPU支持配置：**

```bash
# 构建支持GPU的容器
singularity build --nv scientific-gpu.sif Singularity.def

# 运行GPU容器
singularity exec --nv scientific-gpu.sif nvidia-smi
singularity exec --nv scientific-gpu.sif python3 gpu_test.py
```

### 11.2.3 容器编排与管理

#### 容器注册中心

**私有镜像仓库：**

```bash
# Docker Registry部署
docker run -d \
    --restart=always \
    --name registry \
    -v /opt/registry/data:/var/lib/registry \
    -v /opt/registry/auth:/auth \
    -e REGISTRY_AUTH=htpasswd \
    -e REGISTRY_AUTH_HTPASSWD_REALM="Registry Realm" \
    -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \
    -p 5000:5000 \
    registry:2

# 镜像推送
docker tag scientific-image localhost:5000/scientific-image:latest
docker push localhost:5000/scientific-image:latest
```

**镜像安全扫描：**

```bash
# Trivy安全扫描
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
    aquasec/trivy image scientific-image:latest

# Clair扫描
docker run -p 6060:6060 -d --name clair \
    quay.io/coreos/clair:latest
```

## 11.3 软件版本管理

### 11.3.1 环境模块系统（Environment Modules）

#### Module环境

**模块文件编写：**

```tcl
# /opt/modules/gromacs/2023
#%Module1.0
##
## GROMACS modulefile
##

proc ModulesHelp { } {
    puts stderr "Sets up environment for GROMACS 2023"
}

module-whatis "Sets up environment for GROMACS 2023"

# 设置路径
set prefix /opt/gromacs/2023

prepend-path PATH $prefix/bin
prepend-path LD_LIBRARY_PATH $prefix/lib
prepend-path MANPATH $prefix/share/man

# 设置环境变量
setenv GMXLIB $prefix/share/gromacs/top
setenv GMXDATA $prefix/share/gromacs

# 版本信息
set ModulesVersion "2023"
```

**依赖关系管理：**

```tcl
# /opt/modules/gromacs/2023-impi
#%Module1.0
##
## GROMACS modulefile with Intel MPI
##

module-whatis "GROMACS 2023 with Intel MPI"

# 加载依赖模块
module load intel/2023
module load impi/2023

# 设置路径
set prefix /opt/gromacs/2023-impi
prepend-path PATH $prefix/bin
prepend-path LD_LIBRARY_PATH $prefix/lib
```

#### Lmod模块系统

**Lua脚本编写：**

```lua
-- /opt/lmod/gromacs/2023.lua
help([[
GROMACS 2023 molecular dynamics package
]])

whatis("Name: GROMACS")
whatis("Version: 2023")
whatis("Category: molecular dynamics")
whatis("Description: GROMACS is a versatile package to perform molecular dynamics")

local prefix = "/opt/gromacs/2023"

setenv("GMXLIB", pathJoin(prefix, "share/gromacs/top"))
setenv("GMXDATA", pathJoin(prefix, "share/gromacs"))

prepend_path("PATH", pathJoin(prefix, "bin"))
prepend_path("LD_LIBRARY_PATH", pathJoin(prefix, "lib"))
prepend_path("MANPATH", pathJoin(prefix, "share/man"))

-- 设置默认版本
if (mode() == "load") then
    LmodMessage("GROMACS 2023 loaded")
end
```

**层次化模块：**

```lua
-- /opt/lmod/Core/intel/2023.lua
help([[
Intel Compiler Suite 2023
]])

whatis("Name: Intel Compiler")
whatis("Version: 2023")

family("compiler")

local prefix = "/opt/intel/2023"
prepend_path("PATH", pathJoin(prefix, "bin"))
prepend_path("LD_LIBRARY_PATH", pathJoin(prefix, "lib"))
```

```lua
-- /opt/lmod/compiler/intel/2023/impi/2023.lua
help([[
Intel MPI 2023
]])

whatis("Name: Intel MPI")
whatis("Version: 2023")

depends_on("compiler/intel/2023")

local prefix = "/opt/intel/2023/impi/2023.0.0"
prepend_path("PATH", pathJoin(prefix, "bin"))
prepend_path("LD_LIBRARY_PATH", pathJoin(prefix, "lib"))
```

### 11.3.2 软件包管理系统

#### Spack包管理器

**HPC专用包管理：**

```bash
# Spack安装
git clone https://github.com/spack/spack.git
cd spack
. share/spack/setup-env.sh

# 配置编译器
spack compiler find

# 配置包源
spack mirror add local file:///opt/spack-mirror
spack buildcache list

# 安装软件包
spack install gromacs@2023 +mpi ^openmpi
spack install vasp@6.3.2 +cuda ^cuda

# 创建环境
spack env create my-hpc-env
spack env activate my-hpc-env
spack add gromacs@2023 +mpi
spack concretize
spack install
```

**依赖解析和构建：**

```yaml
# spack.yaml环境配置
spack:
  specs:
  - gromacs@2023 +mpi ^openmpi
  - vasp@6.3.2 +cuda ^cuda
  - python@3.10 +blas ^openblas
  view: true
  concretization: together
```

#### EasyBuild构建系统

**自动化构建流程：**

```python
# EasyConfig文件示例：GROMACS-2023.eb
easyblock = 'ConfigureMake'

name = 'GROMACS'
version = '2023'

homepage = 'http://www.gromacs.org/'
description = "GROMACS is a versatile package to perform molecular dynamics"

toolchain = {'name': 'intel', 'version': '2023'}
toolchainopts = {'usempi': True}

source_urls = ['http://ftp.gromacs.org/pub/gromacs/']
sources = [SOURCELOWER_TAR_GZ]

dependencies = [
    ('IntelMPI', '2023'),
    ('FFTW', '3.3.10'),
]

configopts = '-DCMAKE_INSTALL_PREFIX=%(installdir)s '
configopts += '-DGMX_BUILD_OWN_FFTW=ON '
configopts += '-DGMX_MPI=ON '
configopts += '-DGMX_OPENMP=ON '
configopts += '-DGMX_DOUBLE=OFF '

postinstallcmds = [
    'cd %(installdir)s/share/gromacs/top && ',
    'for file in *.itp; do ln -sf $file %(installdir)s/share/gromacs/top/$(basename $file .itp).rtp; done',
]
```

**软件栈管理：**

```bash
# 构建软件栈
eb --robot --module-syntax=Lua GROMACS-2023.eb

# 管理模块
module use /opt/modules/all
module load GROMACS/2023-intel-2023

# 查看依赖
eb --deptree GROMACS-2023.eb
```

### 11.3.3 版本控制策略

#### 软件版本规划

**LTS版本选择：**

```bash
# 长期支持版本策略
# Python: 3.10.x (LTS)
# GCC: 11.x (LTS)
# OpenMPI: 4.1.x (LTS)
# Intel MPI: 2021.x (LTS)

# 版本矩阵
software_matrix:
  python:
    lts: "3.10.15"
    current: "3.12.0"
    deprecated: ["2.7", "3.6", "3.7"]

  gcc:
    lts: "11.4.0"
    current: "13.2.0"
    deprecated: ["7", "8", "9"]

  openmpi:
    lts: "4.1.6"
    current: "5.0.3"
    deprecated: ["3.x", "2.x"]
```

**升级策略制定：**

```bash
# 升级计划
upgrade_plan:
  phase_1: "测试环境验证"
  phase_2: "小规模试点"
  phase_3: "生产环境部署"
  phase_4: "旧版本退役"

# 兼容性测试
test_matrix:
  - python: 3.10
    numpy: 1.24
    scipy: 1.10
  - python: 3.11
    numpy: 1.25
    scipy: 1.11
```

## 11.4 性能基准测试

### 11.4.1 基准测试套件

#### HPCG（High Performance Conjugate Gradients）

**稀疏矩阵求解器测试：**

```bash
# HPCG下载和编译
wget https://www.hpcg-benchmark.org/downloads/hpcg-3.1.tar.gz
tar -xzf hpcg-3.1.tar.gz
cd hpcg-3.1

# 配置文件
cp setup/Make.unknown setup/Make.custom
# 编辑Make.custom
CC = mpicxx
CXX = mpicxx
MPICXX = mpicxx
CFLAGS = -O3 -DNDEBUG
CXXFLAGS = -O3 -DNDEBUG

make arch=custom -j$(nproc)

# 运行测试
mpirun -np 64 ./xhpcg 128 128 128 60
```

**内存带宽测试：**

```bash
# HPCG内存访问模式
# 1. 随机访问模式
# 2. 步进访问模式
# 3. 跳跃访问模式
# 4. 混合访问模式

# 结果分析
grep "HPCG result is VALID with a GFLOP/s rating" HPCG.dat
# HPCG result is VALID with a GFLOP/s rating of: 1234.56
```

#### STREAM内存带宽测试

**内存复制性能：**

```c
// stream.c 简化版本
#include <stdio.h>
#include <omp.h>
#include <sys/time.h>

#define N 200000000
#define NTIMES 10
#define OFFSET 0

double a[N+OFFSET], b[N+OFFSET], c[N+OFFSET];

static double mysecond(){
    struct timeval tp;
    gettimeofday(&tp, NULL);
    return ( (double) tp.tv_sec + (double) tp.tv_usec * 1.e-6 );
}

int main(){
    int j, k;
    double scalar, times[4][NTIMES];

    /* --- SETUP --- determine precision and check timing --- */
    printf("STREAM version $Revision: 5.10 $\n");
    printf("Array size = %llu, Offset = %d\n" , (unsigned long long) N, OFFSET);
    printf("Total memory required = %.1f MB.\n",
           (3.0 * sizeof(double) * (double) N) / 1048576.0);
    printf("Each test is run %d times, but only\n", NTIMES);
    printf("the *best* time for each is used.\n");

    /* --- MAIN LOOP --- repeat test cases NTIMES times --- */
    scalar = 3.0;
    for (k=0; k<NTIMES; k++)
    {
        times[0][k] = mysecond();
#pragma omp parallel for
        for (j=0; j<N; j++)
            a[j] = b[j] + scalar*c[j];
        times[0][k] = mysecond() - times[0][k];

        times[1][k] = mysecond();
#pragma omp parallel for
        for (j=0; j<N; j++)
            b[j] = scalar*a[j];
        times[1][k] = mysecond() - times[1][k];

        times[2][k] = mysecond();
#pragma omp parallel for
        for (j=0; j<N; j++)
            a[j] = b[j] + c[j];
        times[2][k] = mysecond() - times[2][k];

        times[3][k] = mysecond();
#pragma omp parallel for
        for (j=0; j<N; j++)
            a[j] = b[j] + scalar*c[j];
        times[3][k] = mysecond() - times[3][k];
    }

    /* --- SUMMARY --- */
    for (k=1; k<NTIMES; k++) /* note -- skip first iteration */
    {
        for (j=0; j<4; j++)
        {
            if (times[j][k] < times[j][0]) times[j][0] = times[j][k];
        }
    }

    printf("Function    Best Rate MB/s  Avg time     Min time     Max time\n");
    printf("Copy:        %11.4f     %11.4f   %11.4f   %11.4f\n",
           2.0*8.0*(double)N/1000000./times[0][0],
           times[0][0],
           times[0][0],
           times[0][0]);

    return 0;
}
```

### 11.4.2 应用级基准测试

#### GROMACS性能测试

**标准测试用例：**

```bash
# 下载GROMACS测试用例
wget https://ftp.gromacs.org/pub/benchmarks/gromacs_benchmark_systems-3.0.tar.gz
tar -xzf gromacs_benchmark_systems-3.0.tar.gz
cd gromacs_benchmark_systems-3.0

# 蛋白质-配体系统测试
cd 1AKI
gmx grompp -f md.mdp -c 1AKI_solv_ions.gro -p topol.top -o md.tpr
gmx mdrun -s md.tpr -ntmpi 64 -ntomp 4 -pin on

# 膜蛋白系统测试
cd ../1MEE
gmx grompp -f md.mdp -c 1MEE_solv_ions.gro -p topol.top -o md.tpr
gmx mdrun -s md.tpr -ntmpi 64 -ntomp 4 -pin on
```

**性能分析：**

```bash
# 性能报告生成
gmx mdrun -s md.tpr -resethway -nsteps 50000 -noconfout

# 分析性能数据
grep "Performance" md.log
# Performance: 12345.675 ns/day, 10.237 s/step
```

#### AI/ML基准测试

**MLPerf训练基准：**

```bash
# MLPerf训练套件
git clone https://github.com/mlcommons/training.git
cd training

# ResNet50训练测试
cd/image_classification
python launch_benchmark.py \
    --model-resnet50 \
    --precision=fp32 \
    --mode=training \
    --framework=tensorflow \
    --num-intra-threads=32 \
    --num-inter-threads=1 \
    --batch-size=64 \
    --train-steps=500
```

**推理性能测试：**

```bash
# MLPerf推理测试
cd inference
python run_local.py \
    --backend=tensorrt \
    --scenario=Offline \
    --model=resnet50 \
    --dataset=imagenet \
    --accuracy=true \
    --output=/tmp/mlperf_results
```

### 11.4.3 性能分析工具

#### 性能监控工具

**perf性能分析器：**

```bash
# CPU性能分析
perf record -g -e cycles,instructions,cache-misses,cache-references \
    mpirun -np 64 gmx_mpi mdrun -s md.tpr

# 分析结果
perf report --stdio > perf_report.txt

# 热点函数分析
perf annotate --symbol=compute_forces > annotate_output.txt
```

**Intel VTune Amplifier：**

```bash
# 热点分析
amplxe-cl -collect hotspots -result-dir /tmp/vtune_results \
    mpirun -np 64 gmx_mpi mdrun -s md.tpr

# 内存访问分析
amplxe-cl -collect memory-access -result-dir /tmp/vtune_mem \
    mpirun -np 64 gmx_mpi mdrun -s md.tpr

# 分析结果
amplxe-cl -report hotspots -result-dir /tmp/vtune_results
```

#### 并行性能分析

**MPI通信分析：**

```bash
# TAU性能分析
export TAU_OPTIONS="-optVerbose -optKeepFiles -optTrackHeap"
export TAU_TRACE=1
export TAU_PROFILE=1

tau_exec -T serial,mpi,pthread mpirun -np 64 gmx_mpi mdrun -s md.tpr

# 生成性能报告
pprof -summary md_trace.pprof
```

**负载均衡评估：**

```bash
# 使用gprof进行分析
gcc -pg -O3 -o my_program my_program.c
./my_program
gprof my_program gmon.out > profile.txt

# 分析函数调用时间
grep -A 10 "Function Name" profile.txt
```

### 11.4.4 性能优化实践

#### 编译器优化

**编译选项调优：**

```bash
# GCC优化选项
gcc -O3 -march=native -mtune=native \
    -ffast-math -funroll-loops \
    -ftree-vectorize -fopenmp \
    -o optimized_program program.c

# Intel编译器优化
icc -O3 -xHost -ipo -parallel \
    -qopenmp -qopt-report=5 \
    -o optimized_program program.c

# 数学库选择
# 使用Intel MKL
icc -O3 -mkl=cluster -qopenmp program.c
# 使用OpenBLAS
gcc -O3 -lopenblas program.c
```

**SIMD指令优化：**

```c
// 向量化示例
#include <immintrin.h>

void vectorized_sum(float *a, float *b, float *c, int n) {
    int i;
    __m256 va, vb, vc;

    // 处理8的倍数部分
    for (i = 0; i < n - 7; i += 8) {
        va = _mm256_loadu_ps(&a[i]);
        vb = _mm256_loadu_ps(&b[i]);
        vc = _mm256_add_ps(va, vb);
        _mm256_storeu_ps(&c[i], vc);
    }

    // 处理剩余部分
    for (; i < n; i++) {
        c[i] = a[i] + b[i];
    }
}
```

#### 运行时优化

**进程绑定策略：**

```bash
# OpenMPI进程绑定
mpirun -np 64 --map-by socket:PE=16 --bind-to core \
    gmx_mpi mdrun -s md.tpr

# Intel MPI进程绑定
mpirun -np 64 -genv I_MPI_PIN_DOMAIN=core \
    -genv I_MPI_PIN_PROCESSOR_LIST=0-63 \
    gmx_mpi mdrun -s md.tpr

# NUMA感知绑定
numactl --interleave=all mpirun -np 64 gmx_mpi mdrun -s md.tpr
```

**内存分配优化：**

```c
// 对齐内存分配
#include <stdlib.h>

void *aligned_malloc(size_t size, size_t alignment) {
    void *ptr;
    if (posix_memalign(&ptr, alignment, size) != 0) {
        return NULL;
    }
    return ptr;
}

// 使用示例
float *data = (float*)aligned_malloc(n * sizeof(float), 64);
// ... 使用data ...
free(data);
```

#### I/O性能优化

**并行文件系统优化：**

```bash
# Lustre条带化设置
lfs setstripe -c 8 -S 1M /path/to/output

# MPI-IO优化
mpiexec -np 64 ./io_benchmark --collective --striping=8

# HDF5并行I/O
h5p_set_fapl_mpio(plist_id, comm, info);
h5p_set_dxpl_mpio(xfer_plist, H5FD_MPIO_COLLECTIVE);
```

**缓存策略配置：**

```bash
# 文件系统缓存调优
echo 3 > /proc/sys/vm/drop_caches  # 清理缓存

# 修改缓存策略
echo 1 > /proc/sys/vm/dirty_background_ratio
echo 5 > /proc/sys/vm/dirty_ratio

# 文件预读优化
blockdev --setra 256 /dev/sda
```

## 11.5 软件许可证管理

### 11.5.1 许可证类型

#### 商业软件许可证

**浮动许可证配置：**

```bash
# ANSYS许可证服务器配置
# ansyslmd.ini
SERVER hostname hostid port
VENDOR ansyslmd
USE_SERVER

# 启动许可证服务器
ansyslmd start
ansyslmd status

# 客户端配置
export ANSYSLMD_LICENSE_FILE=port@hostname
```

**集群许可证管理：**

```bash
# MATLAB集群许可证
# matlab_startup.m
parpool('local', 32);

# 批量作业配置
# matlab_batch.sh
#!/bin/bash
export MATLAB_PREFDIR=/shared/matlab_prefs
matlab -batch "run_simulation"
```

#### 开源许可证

**许可证兼容性检查：**

```python
# Python许可证检查脚本
import pkg_resources

def check_license_compatibility():
    installed_packages = [d.project_name for d in pkg_resources.working_set]

    # 关键包许可证检查
    license_matrix = {
        'numpy': 'BSD',
        'scipy': 'BSD',
        'matplotlib': 'PSF',
        'tensorflow': 'Apache 2.0',
        'pytorch': 'BSD'
    }

    for package in installed_packages:
        try:
            dist = pkg_resources.get_distribution(package)
            print(f"{package}: {dist.version}")
        except:
            pass
```

### 11.5.2 许可证服务器配置

#### License Server部署

**高可用配置：**

```bash
# 双机热备许可证服务器
# 主服务器配置
SERVER primary_host primary_hostid 27000
SERVER secondary_host secondary_hostid 27000
USE_SERVER

# 负载均衡配置
# 使用DNS轮询或硬件负载均衡器
export LM_LICENSE_FILE=27000@primary_host:27000@secondary_host
```

**监控和告警：**

```bash
# 许可证使用监控脚本
#!/bin/bash
LICENSE_SERVER="license-server"
PORT="27000"

# 检查许可证服务器状态
lmutil lmstat -c $PORT@$LICENSE_SERVER > /tmp/license_status.txt

# 解析使用情况
USED=$(grep "Users of" /tmp/license_status.txt | awk '{print $6}')
TOTAL=$(grep "Users of" /tmp/license_status.txt | awk '{print $9}')

# 计算使用率
USAGE_RATE=$((USED * 100 / TOTAL))

# 告警阈值检查
if [ $USAGE_RATE -gt 80 ]; then
    echo "WARNING: License usage is $USAGE_RATE%" | mail -s "License Alert" admin@domain.com
fi
```

## 11.6 软件部署自动化

### 11.6.1 配置管理工具

#### Ansible自动化部署

**Playbook编写：**

```yaml
---
# gromacs_deployment.yml
- name: Deploy GROMACS on HPC cluster
  hosts: hpc_nodes
  become: yes
  vars:
    gromacs_version: "2023"
    gromacs_url: "http://ftp.gromacs.org/pub/gromacs/gromacs-2023.tar.gz"
    install_dir: "/opt/gromacs/{{ gromacs_version }}"

  tasks:
    - name: Install system dependencies
      package:
        name:
          - build-essential
          - cmake
          - wget
          - libfftw3-dev
          - libopenmpi-dev
        state: present

    - name: Create installation directory
      file:
        path: "{{ install_dir }}"
        state: directory
        mode: '0755'

    - name: Download GROMACS source
      get_url:
        url: "{{ gromacs_url }}"
        dest: "/tmp/gromacs-{{ gromacs_version }}.tar.gz"

    - name: Extract GROMACS source
      unarchive:
        src: "/tmp/gromacs-{{ gromacs_version }}.tar.gz"
        dest: "/tmp/"
        remote_src: yes

    - name: Compile GROMACS
      shell: |
        cd /tmp/gromacs-{{ gromacs_version }}
        mkdir build && cd build
        cmake .. -DCMAKE_INSTALL_PREFIX={{ install_dir }} \
                 -DGMX_BUILD_OWN_FFTW=ON \
                 -DGMX_MPI=ON \
                 -DGMX_OPENMP=ON
        make -j{{ ansible_processor_cores }}
        make install
      args:
        chdir: /tmp/gromacs-{{ gromacs_version }}

    - name: Create module file
      template:
        src: gromacs_module.j2
        dest: "/opt/modules/gromacs/{{ gromacs_version }}"
        mode: '0644'

    - name: Clean up
      file:
        path: "/tmp/gromacs-{{ gromacs_version }}"
        state: absent
```

**模块文件模板：**

```jinja2
{# gromacs_module.j2 #}
#%Module1.0
##
## GROMACS {{ gromacs_version }} modulefile
##

proc ModulesHelp { } {
    puts stderr "Sets up environment for GROMACS {{ gromacs_version }}"
}

module-whatis "Sets up environment for GROMACS {{ gromacs_version }}"

set prefix {{ install_dir }}

prepend-path PATH {{ prefix }}/bin
prepend-path LD_LIBRARY_PATH {{ prefix }}/lib
prepend-path MANPATH {{ prefix }}/share/man

setenv GMXLIB {{ prefix }}/share/gromacs/top
setenv GMXDATA {{ prefix }}/share/gromacs
```

#### 角色和变量管理

**Ansible角色结构：**

```
roles/
├── gromacs/
│   ├── defaults/
│   │   └── main.yml
│   ├── tasks/
│   │   └── main.yml
│   ├── templates/
│   │   └── gromacs_module.j2
│   └── meta/
│       └── main.yml
└── mpi/
    ├── tasks/
    │   └── main.yml
    └── handlers/
        └── main.yml
```

**变量管理：**

```yaml
# group_vars/hpc_cluster.yml
---
# HPC集群通用配置
cluster_name: "my_hpc_cluster"
admin_user: "hpcadmin"
software_base_dir: "/opt"

# 编译器配置
compiler:
  name: "intel"
  version: "2023"
  path: "/opt/intel/2023"

# MPI配置
mpi:
  name: "openmpi"
  version: "4.1.6"
  path: "/opt/openmpi/4.1.6"

# 软件配置
software_packages:
  gromacs:
    version: "2023"
    dependencies: ["mpi", "fftw"]
  vasp:
    version: "6.3.2"
    dependencies: ["mpi", "blas"]
```

### 11.6.2 CI/CD流水线

#### 自动化构建

**Jenkins流水线：**

```groovy
pipeline {
    agent any

    environment {
        SOFTWARE_BASE = '/opt/software'
        MODULE_DIR = '/opt/modules'
    }

    stages {
        stage('Setup Environment') {
            steps {
                sh '''
                    # 安装依赖
                    sudo apt-get update
                    sudo apt-get install -y build-essential cmake wget
                '''
            }
        }

        stage('Build GROMACS') {
            steps {
                sh '''
                    # 下载源码
                    wget http://ftp.gromacs.org/pub/gromacs/gromacs-2023.tar.gz
                    tar -xzf gromacs-2023.tar.gz

                    # 编译安装
                    cd gromacs-2023
                    mkdir build && cd build
                    cmake .. -DCMAKE_INSTALL_PREFIX=${SOFTWARE_BASE}/gromacs/2023 \
                             -DGMX_BUILD_OWN_FFTW=ON \
                             -DGMX_MPI=ON
                    make -j$(nproc)
                    sudo make install
                '''
            }
        }

        stage('Create Module') {
            steps {
                sh '''
                    # 创建模块文件
                    sudo mkdir -p ${MODULE_DIR}/gromacs
                    cat > ${MODULE_DIR}/gromacs/2023 << 'EOF'
#%Module1.0
##
## GROMACS 2023 modulefile
##

prepend-path PATH ${SOFTWARE_BASE}/gromacs/2023/bin
prepend-path LD_LIBRARY_PATH ${SOFTWARE_BASE}/gromacs/2023/lib
setenv GMXLIB ${SOFTWARE_BASE}/gromacs/2023/share/gromacs/top
EOF
                '''
            }
        }

        stage('Test Installation') {
            steps {
                sh '''
                    # 测试安装
                    module load gromacs/2023
                    gmx --version

                    # 运行简单测试
                    gmx check -f test.gro
                '''
            }
        }

        stage('Deploy') {
            steps {
                script {
                    // 部署到生产环境
                    sh '''
                        # 复制到目标系统
                        rsync -av ${SOFTWARE_BASE}/gromacs/ /target/system/opt/gromacs/
                        rsync -av ${MODULE_DIR}/gromacs/ /target/system/opt/modules/gromacs/
                    '''
                }
            }
        }
    }

    post {
        always {
            // 清理工作
            sh 'rm -rf gromacs-2023*'
        }
        success {
            echo 'Build and deployment successful!'
        }
        failure {
            echo 'Build or deployment failed!'
        }
    }
}
```

#### 质量保证

**自动化测试套件：**

```python
# test_software_installation.py
import subprocess
import unittest
import os

class SoftwareInstallationTest(unittest.TestCase):
    def setUp(self):
        self.software_base = '/opt/software'
        self.module_dir = '/opt/modules'

    def test_gromacs_installation(self):
        """测试GROMACS安装"""
        # 检查二进制文件
        gromacs_bin = os.path.join(self.software_base, 'gromacs/2023/bin/gmx')
        self.assertTrue(os.path.exists(gromacs_bin))

        # 测试版本信息
        result = subprocess.run(['gmx', '--version'], capture_output=True, text=True)
        self.assertIn('GROMACS', result.stdout)

    def test_module_file(self):
        """测试模块文件"""
        module_file = os.path.join(self.module_dir, 'gromacs/2023')
        self.assertTrue(os.path.exists(module_file))

    def test_mpi_integration(self):
        """测试MPI集成"""
        # 测试MPI-GROMACS
        result = subprocess.run(['mpirun', '-np', '2', 'gmx_mpi', '--version'],
                              capture_output=True, text=True)
        self.assertEqual(result.returncode, 0)

if __name__ == '__main__':
    unittest.main()
```

**性能回归测试：**

```bash
#!/bin/bash
# performance_regression_test.sh

# 定义基准性能
BASELINE_PERFORMANCE=10000  # ns/day

# 运行性能测试
echo "Running performance test..."
mpirun -np 64 gmx_mpi mdrun -s md.tpr -nsteps 10000 > perf_test.log

# 提取性能数据
CURRENT_PERFORMANCE=$(grep "Performance" perf_test.log | awk '{print $3}')

# 检查性能回归
if [ $(echo "$CURRENT_PERFORMANCE < $BASELINE_PERFORMANCE * 0.95" | bc) -eq 1 ]; then
    echo "ERROR: Performance regression detected!"
    echo "Expected: $BASELINE_PERFORMANCE ns/day"
    echo "Actual: $CURRENT_PERFORMANCE ns/day"
    exit 1
else
    echo "Performance test passed: $CURRENT_PERFORMANCE ns/day"
fi
```

## 总结

本章详细介绍了HPC环境下的科学计算软件管理，包括：

1. **常用科学计算软件安装**：涵盖了数值计算、工程仿真、分子模拟、计算化学和CFD软件的安装配置
2. **容器化部署**：Docker和Singularity容器技术在HPC环境中的应用
3. **软件版本管理**：环境模块系统、包管理器和版本控制策略
4. **性能基准测试**：各类基准测试套件和性能分析工具的使用
5. **软件许可证管理**：许可证类型、服务器配置和使用监控
6. **软件部署自动化**：配置管理工具和CI/CD流水线的实现

这些内容为HPC运维工程师提供了完整的科学计算软件管理框架，确保软件环境的稳定性、性能和可维护性。