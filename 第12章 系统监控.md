# ç¬¬12ç«  ç³»ç»Ÿç›‘æ§

> HPCé›†ç¾¤ç³»ç»Ÿç›‘æ§ä¸æ€§èƒ½ç®¡ç†å®è·µæŒ‡å—

## ğŸ“Š æœ¬ç« æ¦‚è¿°

ç³»ç»Ÿç›‘æ§æ˜¯HPCè¿ç»´çš„æ ¸å¿ƒæŠ€èƒ½ä¹‹ä¸€ã€‚æœ¬ç« å°†æ·±å…¥ä»‹ç»HPCé›†ç¾¤çš„ç›‘æ§ä½“ç³»æ„å»ºï¼ŒåŒ…æ‹¬ç›‘æ§å·¥å…·é€‰æ‹©ã€æ€§èƒ½æŒ‡æ ‡æ”¶é›†ã€å‘Šè­¦ç³»ç»Ÿé…ç½®å’Œå¯è§†åŒ–ç›‘æ§é¢æ¿æ­å»ºã€‚

**å­¦ä¹ ç›®æ ‡ï¼š**
- æŒæ¡ä¸»æµç›‘æ§å·¥å…·çš„éƒ¨ç½²å’Œé…ç½®
- ç†è§£HPCé›†ç¾¤çš„å…³é”®æ€§èƒ½æŒ‡æ ‡
- å­¦ä¼šé…ç½®æœ‰æ•ˆçš„å‘Šè­¦ç­–ç•¥
- æ„å»ºç›´è§‚çš„ç›‘æ§å¯è§†åŒ–ç³»ç»Ÿ

## ğŸ¯ ç›‘æ§ä½“ç³»æ¶æ„

### 12.1 ç›‘æ§å·¥å…·é€‰æ‹©

#### 12.1.1 ç°ä»£åŸºç¡€è®¾æ–½ç›‘æ§ (Prometheus + VictoriaMetrics)

**Prometheus ç”Ÿæ€ï¼š**
- **Prometheus**: æ ¸å¿ƒæŒ‡æ ‡æ”¶é›†ä¸å­˜å‚¨ï¼ˆçŸ­æœŸï¼‰
- **VictoriaMetrics**: é•¿æœŸå­˜å‚¨ä¸æ°´å¹³æ‰©å±•ï¼ˆæ¨èæ›¿ä»£ Thanosï¼‰
- **Node Exporter**: ç¡¬ä»¶æŒ‡æ ‡é‡‡é›†
- **DCGM Exporter**: NVIDIA GPU æŒ‡æ ‡é‡‡é›†

**å¿«é€Ÿéƒ¨ç½² (Docker Compose)ï¼š**

```yaml
version: '3.8'
services:
  victoria-metrics:
    image: victoriametrics/victoria-metrics:v1.93.0
    ports:
      - "8428:8428"
    volumes:
      - vmdata:/storage
    command:
      - "-storageDataPath=/storage"
      - "-retentionPeriod=1y"

  prometheus:
    image: prom/prometheus:v2.45.0
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.remoteWrite.url=http://victoria-metrics:8428/api/v1/write"

  grafana:
    image: grafana/grafana:10.0.0
    ports:
      - "3000:3000"

volumes:
  vmdata:
```

#### 12.1.2 Zabbixç›‘æ§ç³»ç»Ÿ

**Zabbixç®€ä»‹ï¼š**
- ä¼ä¸šçº§å¼€æºç›‘æ§è§£å†³æ–¹æ¡ˆ
- æ”¯æŒåˆ†å¸ƒå¼ç›‘æ§æ¶æ„
- å¼ºå¤§çš„æ•°æ®å­˜å‚¨å’Œå¯è§†åŒ–èƒ½åŠ›

**é€‚ç”¨åœºæ™¯ï¼š**
- å¤§è§„æ¨¡é›†ç¾¤ç›‘æ§
- æ€§èƒ½æ•°æ®é•¿æœŸå­˜å‚¨
- å¤æ‚çš„å‘Šè­¦ç­–ç•¥

**å¿«é€Ÿéƒ¨ç½²ï¼š**

```bash
# 1. å®‰è£…Zabbixä»“åº“
sudo rpm -Uvh https://repo.zabbix.com/zabbix/6.0/rhel/8/x86_64/zabbix-release-6.0-4.el8.noarch.rpm
sudo dnf clean all

# 2. å®‰è£…Zabbix Server
sudo dnf install zabbix-server-mysql zabbix-web-mysql zabbix-apache-conf zabbix-sql-scripts zabbix-selinux-policy zabbix-agent

# 3. é…ç½®æ•°æ®åº“
sudo dnf install mariadb-server
sudo systemctl enable mariadb
sudo systemctl start mariadb

# åˆ›å»ºæ•°æ®åº“
mysql -u root -p <<EOF
CREATE DATABASE zabbix CHARACTER SET UTF8 COLLATE UTF8_BIN;
CREATE USER 'zabbix'@'localhost' IDENTIFIED BY 'password';
GRANT ALL PRIVILEGES ON zabbix.* TO 'zabbix'@'localhost';
FLUSH PRIVILEGES;
EOF

# å¯¼å…¥åˆå§‹æ•°æ®
zcat /usr/share/doc/zabbix-sql-scripts/mysql/server.sql.gz | mysql -uzabbix -p zabbix

# 4. é…ç½®Zabbix Server
sudo vim /etc/zabbix/zabbix_server.conf
# DBHost=localhost
# DBName=zabbix
# DBUser=zabbix
# DBPassword=password

# 5. å¯åŠ¨æœåŠ¡
sudo systemctl restart zabbix-server zabbix-agent httpd
sudo systemctl enable zabbix-server zabbix-agent httpd
```

**Zabbixç›‘æ§æ¨¡æ¿ï¼š**

```json
{
    "zabbix_export": {
        "version": "6.0",
        "templates": [
            {
                "template": "HPC Compute Node",
                "groups": [
                    {
                        "name": "Templates"
                    }
                ],
                "items": [
                    {
                        "name": "CPU Usage",
                        "key": "system.cpu.util[,idle]",
                        "delay": "30s"
                    },
                    {
                        "name": "Memory Usage",
                        "key": "vm.memory.size[pavailable]",
                        "delay": "30s"
                    },
                    {
                        "name": "Disk Usage",
                        "key": "vfs.fs.size[/,pused]",
                        "delay": "30s"
                    },
                    {
                        "name": "Load Average",
                        "key": "system.cpu.load[all,avg1]",
                        "delay": "30s"
                    }
                ],
                "triggers": [
                    {
                        "expression": "{HPC Compute Node:system.cpu.util[,idle].last()}<20",
                        "name": "High CPU Usage",
                        "priority": "4"
                    },
                    {
                        "expression": "{HPC Compute Node:vm.memory.size[pavailable].last()}<10",
                        "name": "Low Memory",
                        "priority": "4"
                    }
                ]
            }
        ]
    }
}
```

#### 12.1.3 å…¶ä»–ç›‘æ§å·¥å…·å¯¹æ¯”

| å·¥å…· | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **Nagios** | æˆç†Ÿç¨³å®šï¼Œæ’ä»¶ä¸°å¯Œ | é…ç½®å¤æ‚ï¼Œå¯è§†åŒ–å¼± | åŸºç¡€ç›‘æ§ï¼ŒæœåŠ¡æ£€æŸ¥ |
| **Zabbix** | åŠŸèƒ½å…¨é¢ï¼Œå¯è§†åŒ–å¥½ | èµ„æºæ¶ˆè€—å¤§ | ä¼ä¸šçº§ç›‘æ§ |
| **Prometheus** | äº‘åŸç”Ÿï¼Œçµæ´» | å­¦ä¹ æ›²çº¿é™¡ | å®¹å™¨åŒ–ç¯å¢ƒ |
| **Ganglia** | HPCä¸“ç”¨ï¼Œè½»é‡ | åŠŸèƒ½ç›¸å¯¹ç®€å• | å¤§è§„æ¨¡é›†ç¾¤ |

### 12.2 æ€§èƒ½æŒ‡æ ‡æ”¶é›†

#### 12.2.1 HPCå…³é”®æ€§èƒ½æŒ‡æ ‡

**è®¡ç®—èŠ‚ç‚¹æŒ‡æ ‡ï¼š**
- CPUä½¿ç”¨ç‡å’Œè´Ÿè½½
- å†…å­˜ä½¿ç”¨ç‡å’Œäº¤æ¢ç©ºé—´
- ç½‘ç»œå¸¦å®½å’Œå»¶è¿Ÿ
- å­˜å‚¨I/Oæ€§èƒ½
- æ¸©åº¦å’ŒåŠŸè€—

**é›†ç¾¤çº§æŒ‡æ ‡ï¼š**
- ä½œä¸šé˜Ÿåˆ—çŠ¶æ€
- èµ„æºåˆ©ç”¨ç‡
- ç½‘ç»œæ‹“æ‰‘çŠ¶æ€
- å­˜å‚¨ç³»ç»Ÿæ€§èƒ½

**åº”ç”¨çº§æŒ‡æ ‡ï¼š**
- MPIé€šä¿¡æ•ˆç‡
- å¹¶è¡Œä½œä¸šæ€§èƒ½
- åº”ç”¨ç¨‹åºå“åº”æ—¶é—´

#### 12.2.2 æŒ‡æ ‡æ”¶é›†å®è·µ

**CPUå’Œå†…å­˜ç›‘æ§è„šæœ¬ï¼š**

```bash
#!/bin/bash
# /opt/monitoring/system_metrics.sh

HOSTNAME=$(hostname)
TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')

# CPUæŒ‡æ ‡
CPU_IDLE=$(top -bn1 | grep "Cpu(s)" | awk '{print $8}' | sed 's/%id,//')
CPU_LOAD=$(uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | sed 's/,//')

# å†…å­˜æŒ‡æ ‡
MEM_TOTAL=$(free -m | awk 'NR==2{print $2}')
MEM_USED=$(free -m | awk 'NR==2{print $3}')
MEM_PERCENT=$(echo "scale=2; $MEM_USED * 100 / $MEM_TOTAL" | bc)

# ç½‘ç»œæŒ‡æ ‡
NET_RX=$(cat /proc/net/dev | grep eth0 | awk '{print $2}')
NET_TX=$(cat /proc/net/dev | grep eth0 | awk '{print $10}')

# ç£ç›˜æŒ‡æ ‡
DISK_USAGE=$(df -h / | awk 'NR==2{print $5}' | sed 's/%//')

# è¾“å‡ºæ ¼å¼åŒ–æ•°æ®
echo "$TIMESTAMP,$HOSTNAME,cpu_idle,$CPU_IDLE"
echo "$TIMESTAMP,$HOSTNAME,cpu_load,$CPU_LOAD"
echo "$TIMESTAMP,$HOSTNAME,memory_usage,$MEM_PERCENT"
echo "$TIMESTAMP,$HOSTNAME,disk_usage,$DISK_USAGE"
echo "$TIMESTAMP,$HOSTNAME,network_rx,$NET_RX"
echo "$TIMESTAMP,$HOSTNAME,network_tx,$NET_TX"

# å†™å…¥ç›‘æ§æ–‡ä»¶
echo "$TIMESTAMP,$HOSTNAME,$CPU_IDLE,$CPU_LOAD,$MEM_PERCENT,$DISK_USAGE,$NET_RX,$NET_TX" >> /var/log/system_metrics.log
```

**ç½‘ç»œæ€§èƒ½ç›‘æ§ï¼š**

```bash
#!/bin/bash
# /opt/monitoring/network_metrics.sh

# æµ‹è¯•ç½‘ç»œå»¶è¿Ÿ
PING_RESULT=$(ping -c 5 compute-node-01 | tail -1 | awk -F'/' '{print $5}')

# æµ‹è¯•ç½‘ç»œå¸¦å®½
if command -v iperf3 &> /dev/null; then
    BANDWIDTH=$(iperf3 -c compute-node-01 -t 10 -f M | grep "sender" | awk '{print $7}')
else
    BANDWIDTH="N/A"
fi

echo "$(date),$(hostname),network_latency,$PING_RESULT"
echo "$(date),$(hostname),network_bandwidth,$BANDWIDTH"
```

**å­˜å‚¨I/Oç›‘æ§ï¼š**

```bash
#!/bin/bash
# /opt/monitoring/storage_metrics.sh

# ç£ç›˜I/Oç»Ÿè®¡
IO_STATS=$(iostat -x 1 1 | grep -E "sda|nvme" | awk '{print $4","$5","$10}')

# LUSTREæ–‡ä»¶ç³»ç»ŸçŠ¶æ€
if mount | grep -q lustre; then
    LUSTRE_STATS=$(lfs df -h | tail -1 | awk '{print $5}' | sed 's/%//')
else
    LUSTRE_STATS="N/A"
fi

echo "$(date),$(hostname),io_read,$IO_STATS"
echo "$(date),$(hostname),lustre_usage,$LUSTRE_STATS"
```

#### 12.2.3 GPU ç›‘æ§ (DCGM-Exporter)

åœ¨ AI/HPC é›†ç¾¤ä¸­ï¼ŒGPU ç›‘æ§è‡³å…³é‡è¦ã€‚ä½¿ç”¨ NVIDIA DCGM-Exporter æ”¶é›†æ˜¾å­˜ã€åˆ©ç”¨ç‡ã€æ¸©åº¦å’ŒåŠŸè€—ã€‚

```bash
# å¯åŠ¨ DCGM-Exporter
docker run -d --gpus all --rm -p 9400:9400 \
   nvcr.io/nvidia/k8s/dcgm-exporter:3.2.5-3.1.7-ubuntu22.04
```

**Prometheus é…ç½®æ·»åŠ ï¼š**

```yaml
  - job_name: 'gpu-metrics'
    static_configs:
      - targets: ['compute-node-01:9400', 'compute-node-02:9400']
```

**å…³é”® GPU æŒ‡æ ‡ï¼š**
- `DCGM_FI_DEV_GPU_UTIL`: GPU æ ¸å¿ƒåˆ©ç”¨ç‡
- `DCGM_FI_DEV_MEM_COPY_UTIL`: æ˜¾å­˜å¸¦å®½åˆ©ç”¨ç‡
- `DCGM_FI_DEV_FB_USED`: æ˜¾å­˜ä½¿ç”¨é‡
- `DCGM_FI_DEV_POWER_USAGE`: å®æ—¶åŠŸè€— (ç“¦ç‰¹)
- `DCGM_FI_DEV_XID_ERRORS`: GPU ç¡¬ä»¶é”™è¯¯ä»£ç  (å…³é”®å‘Šè­¦æŒ‡æ ‡)


### 12.3 å‘Šè­¦ç³»ç»Ÿé…ç½®

#### 12.3.1 å‘Šè­¦ç­–ç•¥è®¾è®¡

**å‘Šè­¦çº§åˆ«å®šä¹‰ï¼š**
- **Critical**: ç³»ç»Ÿæ•…éšœï¼Œç«‹å³å¤„ç†
- **Warning**: æ€§èƒ½ä¸‹é™ï¼Œéœ€è¦å…³æ³¨
- **Info**: ä¿¡æ¯é€šçŸ¥ï¼Œè®°å½•çŠ¶æ€

**å‘Šè­¦é˜ˆå€¼è®¾ç½®ï¼š**

```bash
# /opt/monitoring/alert_thresholds.conf
# CPUå‘Šè­¦é˜ˆå€¼
CPU_CRITICAL=90
CPU_WARNING=80

# å†…å­˜å‘Šè­¦é˜ˆå€¼
MEM_CRITICAL=95
MEM_WARNING=85

# ç£ç›˜å‘Šè­¦é˜ˆå€¼
DISK_CRITICAL=90
DISK_WARNING=80

# ç½‘ç»œå»¶è¿Ÿé˜ˆå€¼(ms)
NET_LATENCY_CRITICAL=100
NET_LATENCY_WARNING=50

# è´Ÿè½½é˜ˆå€¼
LOAD_CRITICAL=8.0
LOAD_WARNING=6.0
```

#### 12.3.2 å‘Šè­¦è„šæœ¬å®ç°

```bash
#!/bin/bash
# /opt/monitoring/check_alerts.sh

source /opt/monitoring/alert_thresholds.conf
HOSTNAME=$(hostname)
TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')

# è¯»å–æœ€æ–°æŒ‡æ ‡æ•°æ®
LATEST_METRICS=$(tail -1 /var/log/system_metrics.log)
IFS=',' read -r ts host cpu_idle cpu_load mem_usage disk_usage net_rx net_tx <<< "$LATEST_METRICS"

# CPUå‘Šè­¦æ£€æŸ¥
CPU_USAGE=$(echo "100 - $cpu_idle" | bc)
if (( $(echo "$CPU_USAGE >= $CPU_CRITICAL" | bc -l) )); then
    echo "$TIMESTAMP,$HOSTNAME,CPU,Critical,CPU usage is $CPU_USAGE%" >> /var/log/alerts.log
    /opt/monitoring/send_alert.sh "CRITICAL" "CPU usage on $HOSTNAME is $CPU_USAGE%"
elif (( $(echo "$CPU_USAGE >= $CPU_WARNING" | bc -l) )); then
    echo "$TIMESTAMP,$HOSTNAME,CPU,Warning,CPU usage is $CPU_USAGE%" >> /var/log/alerts.log
    /opt/monitoring/send_alert.sh "WARNING" "CPU usage on $HOSTNAME is $CPU_USAGE%"
fi

# å†…å­˜å‘Šè­¦æ£€æŸ¥
if (( $(echo "$mem_usage >= $MEM_CRITICAL" | bc -l) )); then
    echo "$TIMESTAMP,$HOSTNAME,Memory,Critical,Memory usage is $mem_usage%" >> /var/log/alerts.log
    /opt/monitoring/send_alert.sh "CRITICAL" "Memory usage on $HOSTNAME is $mem_usage%"
elif (( $(echo "$mem_usage >= $MEM_WARNING" | bc -l) )); then
    echo "$TIMESTAMP,$HOSTNAME,Memory,Warning,Memory usage is $mem_usage%" >> /var/log/alerts.log
    /opt/monitoring/send_alert.sh "WARNING" "Memory usage on $HOSTNAME is $mem_usage%"
fi

# ç£ç›˜å‘Šè­¦æ£€æŸ¥
if (( disk_usage >= DISK_CRITICAL )); then
    echo "$TIMESTAMP,$HOSTNAME,Disk,Critical,Disk usage is ${disk_usage}%" >> /var/log/alerts.log
    /opt/monitoring/send_alert.sh "CRITICAL" "Disk usage on $HOSTNAME is ${disk_usage}%"
elif (( disk_usage >= DISK_WARNING )); then
    echo "$TIMESTAMP,$HOSTNAME,Disk,Warning,Disk usage is ${disk_usage}%" >> /var/log/alerts.log
    /opt/monitoring/send_alert.sh "WARNING" "Disk usage on $HOSTNAME is ${disk_usage}%"
fi

# è´Ÿè½½å‘Šè­¦æ£€æŸ¥
if (( $(echo "$cpu_load >= $LOAD_CRITICAL" | bc -l) )); then
    echo "$TIMESTAMP,$HOSTNAME,Load,Critical,Load average is $cpu_load" >> /var/log/alerts.log
    /opt/monitoring/send_alert.sh "CRITICAL" "Load average on $HOSTNAME is $cpu_load"
elif (( $(echo "$cpu_load >= $LOAD_WARNING" | bc -l) )); then
    echo "$TIMESTAMP,$HOSTNAME,Load,Warning,Load average is $cpu_load" >> /var/log/alerts.log
    /opt/monitoring/send_alert.sh "WARNING" "Load average on $HOSTNAME is $cpu_load"
fi
```

#### 12.3.3 å‘Šè­¦é€šçŸ¥ç³»ç»Ÿ

```bash
#!/bin/bash
# /opt/monitoring/send_alert.sh

ALERT_LEVEL=$1
MESSAGE=$2
HOSTNAME=$(hostname)

# é‚®ä»¶é€šçŸ¥é…ç½®
ADMIN_EMAIL="admin@hpc.example.com"
SLACK_WEBHOOK="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"

# å‘é€é‚®ä»¶
echo "Alert from $HOSTNAME: $MESSAGE" | mail -s "[$ALERT_LEVEL] HPC Alert" $ADMIN_EMAIL

# å‘é€Slacké€šçŸ¥
if [ "$ALERT_LEVEL" = "CRITICAL" ]; then
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"ğŸš¨ [$ALERT_LEVEL] $MESSAGE on $HOSTNAME\"}" \
        $SLACK_WEBHOOK
elif [ "$ALERT_LEVEL" = "WARNING" ]; then
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"âš ï¸ [$ALERT_LEVEL] $MESSAGE on $HOSTNAME\"}" \
        $SLACK_WEBHOOK
fi

# è®°å½•åˆ°ç³»ç»Ÿæ—¥å¿—
logger -p local0.error "[$ALERT_LEVEL] $MESSAGE on $HOSTNAME"
```

#### 12.3.4 Nagioså‘Šè­¦é…ç½®

```bash
# /usr/local/nagios/etc/objects/commands.cfg
define command{
    command_name    notify-service-by-email
    command_line    /usr/bin/printf "%b" "Service Alert: $HOSTNAME$/$SERVICEDESC$ is $SERVICESTATE$\n\nInfo: $SERVICEOUTPUT$" | /bin/mail -s "[$SERVICESTATE$] $HOSTNAME$/$SERVICEDESC$" $CONTACTEMAIL$
}

define command{
    command_name    check-load
    command_line    /usr/local/nagios/libexec/check_load -w 15,10,5 -c 30,25,20
}

define command{
    command_name    check-memory
    command_line    /usr/local/nagios/libexec/check_memory -w 80 -c 90
}
```

**æœåŠ¡å®šä¹‰ï¼š**

```bash
# /usr/local/nagios/etc/objects/services.cfg
define service{
    use                 generic-service
    host_name           compute-node-01
    service_description CPU Load
    check_command       check-load
    notifications_enabled   1
}

define service{
    use                 generic-service
    host_name           compute-node-01
    service_description Memory Usage
    check_command       check-memory
    notifications_enabled   1
}
```

### 12.4 å¯è§†åŒ–ç›‘æ§é¢æ¿

#### 12.4.1 Grafanaç›‘æ§é¢æ¿

**å®‰è£…Grafanaï¼š**

```bash
# 1. å®‰è£…Grafana
sudo yum install -y grafana

# 2. å¯åŠ¨æœåŠ¡
sudo systemctl daemon-reload
sudo systemctl enable grafana-server
sudo systemctl start grafana-server

# 3. è®¿é—® http://localhost:3000
# é»˜è®¤ç”¨æˆ·å/å¯†ç : admin/admin
```

**Grafanaæ•°æ®æºé…ç½®ï¼š**

```bash
# é…ç½®InfluxDBæ•°æ®æº
# 1. åœ¨Grafana Webç•Œé¢æ·»åŠ æ•°æ®æº
# 2. é€‰æ‹©InfluxDB
# 3. é…ç½®è¿æ¥ä¿¡æ¯:
#    - URL: http://localhost:8086
#    - Database: hpc_monitoring
#    - User: grafana
#    - Password: password
```

**Grafanaä»ªè¡¨æ¿JSONé…ç½®ï¼š**

```json
{
  "dashboard": {
    "id": null,
    "title": "HPC Cluster Monitoring",
    "tags": ["hpc", "monitoring"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "CPU Usage Overview",
        "type": "graph",
        "targets": [
          {
            "refId": "A",
            "query": "SELECT mean(\"usage_idle\") FROM \"cpu\" WHERE $timeFilter GROUP BY time($interval) fill(null)"
          }
        ],
        "yAxes": [
          {
            "label": "Percentage",
            "min": 0,
            "max": 100
          }
        ]
      },
      {
        "id": 2,
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "refId": "A",
            "query": "SELECT mean(\"used_percent\") FROM \"mem\" WHERE $timeFilter GROUP BY time($interval) fill(null)"
          }
        ]
      },
      {
        "id": 3,
        "title": "Network Bandwidth",
        "type": "graph",
        "targets": [
          {
            "refId": "A",
            "query": "SELECT mean(\"bytes_recv\") FROM \"net\" WHERE $timeFilter GROUP BY time($interval) fill(null)"
          },
          {
            "refId": "B",
            "query": "SELECT mean(\"bytes_sent\") FROM \"net\" WHERE $timeFilter GROUP BY time($interval) fill(null)"
          }
        ]
      },
      {
        "id": 4,
        "title": "Disk Usage",
        "type": "stat",
        "targets": [
          {
            "refId": "A",
            "query": "SELECT last(\"used_percent\") FROM \"disk\" WHERE $timeFilter GROUP BY \"path\""
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

#### 12.4.2 è‡ªå®šä¹‰ç›‘æ§ä»ªè¡¨æ¿

**HTMLç›‘æ§é¢æ¿ï¼š**

```html
<!DOCTYPE html>
<html>
<head>
    <title>HPC Cluster Monitor</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .dashboard { display: grid; grid-template-columns: repeat(2, 1fr); gap: 20px; }
        .card { border: 1px solid #ddd; padding: 15px; border-radius: 5px; }
        .metric-value { font-size: 24px; font-weight: bold; }
        .status-ok { color: green; }
        .status-warning { color: orange; }
        .status-critical { color: red; }
        .chart-container { height: 300px; }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
    <h1>HPC Cluster Monitoring Dashboard</h1>
    <div class="dashboard">
        <div class="card">
            <h3>CPU Usage</h3>
            <div class="metric-value" id="cpu-value">0%</div>
            <div class="chart-container">
                <canvas id="cpu-chart"></canvas>
            </div>
        </div>
        <div class="card">
            <h3>Memory Usage</h3>
            <div class="metric-value" id="mem-value">0%</div>
            <div class="chart-container">
                <canvas id="mem-chart"></canvas>
            </div>
        </div>
        <div class="card">
            <h3>Load Average</h3>
            <div class="metric-value" id="load-value">0.00</div>
        </div>
        <div class="card">
            <h3>Network Status</h3>
            <div id="network-status">Checking...</div>
        </div>
    </div>

    <script>
        // CPUå›¾è¡¨é…ç½®
        const cpuCtx = document.getElementById('cpu-chart').getContext('2d');
        const cpuChart = new Chart(cpuCtx, {
            type: 'line',
            data: {
                labels: [],
                datasets: [{
                    label: 'CPU Usage %',
                    data: [],
                    borderColor: 'rgb(75, 192, 192)',
                    tension: 0.1
                }]
            },
            options: {
                responsive: true,
                scales: {
                    y: { beginAtZero: true, max: 100 }
                }
            }
        });

        // è·å–ç›‘æ§æ•°æ®
        async function fetchMetrics() {
            try {
                const response = await fetch('/api/metrics');
                const data = await response.json();

                // æ›´æ–°CPUæ˜¾ç¤º
                const cpuUsage = 100 - data.cpu_idle;
                document.getElementById('cpu-value').textContent = cpuUsage + '%';
                document.getElementById('cpu-value').className = 'metric-value ' + getStatusClass(cpuUsage, 80, 90);

                // æ›´æ–°å›¾è¡¨
                cpuChart.data.labels.push(new Date().toLocaleTimeString());
                cpuChart.data.datasets[0].data.push(cpuUsage);
                if (cpuChart.data.labels.length > 20) {
                    cpuChart.data.labels.shift();
                    cpuChart.data.datasets[0].data.shift();
                }
                cpuChart.update();

                // æ›´æ–°å†…å­˜æ˜¾ç¤º
                document.getElementById('mem-value').textContent = data.memory_usage + '%';
                document.getElementById('mem-value').className = 'metric-value ' + getStatusClass(data.memory_usage, 80, 90);

                // æ›´æ–°è´Ÿè½½
                document.getElementById('load-value').textContent = data.load_average;

            } catch (error) {
                console.error('Error fetching metrics:', error);
            }
        }

        function getStatusClass(value, warning, critical) {
            if (value >= critical) return 'status-critical';
            if (value >= warning) return 'status-warning';
            return 'status-ok';
        }

        // å®šæœŸæ›´æ–°æ•°æ®
        setInterval(fetchMetrics, 5000);
        fetchMetrics(); // ç«‹å³è·å–ä¸€æ¬¡æ•°æ®
    </script>
</body>
</html>
```

**Pythonç›‘æ§APIï¼š**

```python
#!/usr/bin/env python3
# /opt/monitoring/api_server.py

from flask import Flask, jsonify
import subprocess
import re
from datetime import datetime

app = Flask(__name__)

def get_system_metrics():
    """è·å–ç³»ç»ŸæŒ‡æ ‡"""
    # CPUä¿¡æ¯
    cpu_idle = subprocess.getoutput("top -bn1 | grep 'Cpu(s)' | awk '{print $8}' | sed 's/%id,//'")
    cpu_load = subprocess.getoutput("uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | sed 's/,//'")

    # å†…å­˜ä¿¡æ¯
    mem_info = subprocess.getoutput("free -m | awk 'NR==2{printf \"%.2f\", $3*100/$2}'")

    # ç£ç›˜ä¿¡æ¯
    disk_usage = subprocess.getoutput("df -h / | awk 'NR==2{print $5}' | sed 's/%//'")

    return {
        'timestamp': datetime.now().isoformat(),
        'cpu_idle': float(cpu_idle),
        'cpu_load': float(cpu_load),
        'memory_usage': float(mem_info),
        'disk_usage': int(disk_usage),
        'hostname': subprocess.getoutput('hostname')
    }

@app.route('/api/metrics')
def api_metrics():
    """APIç«¯ç‚¹è¿”å›ç›‘æ§æ•°æ®"""
    return jsonify(get_system_metrics())

@app.route('/api/alerts')
def api_alerts():
    """APIç«¯ç‚¹è¿”å›å‘Šè­¦ä¿¡æ¯"""
    try:
        with open('/var/log/alerts.log', 'r') as f:
            alerts = f.readlines()
        return jsonify([line.strip().split(',') for line in alerts[-10:]])
    except FileNotFoundError:
        return jsonify([])

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080, debug=True)
```

#### 12.4.3 é›†ç¾¤çº§ç›‘æ§è§†å›¾

**é›†ç¾¤çŠ¶æ€èšåˆè„šæœ¬ï¼š**

```bash
#!/bin/bash
# /opt/monitoring/cluster_status.sh

CLUSTER_NODES="compute-node-01 compute-node-02 compute-node-03 compute-node-04"
STATUS_FILE="/var/log/cluster_status.json"

# æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€
echo '{"timestamp": "'$(date -Iseconds)'", "nodes": [' > $STATUS_FILE

FIRST=true
for node in $CLUSTER_NODES; do
    if [ "$FIRST" = true ]; then
        FIRST=false
    else
        echo ',' >> $STATUS_FILE
    fi

    # æ£€æŸ¥èŠ‚ç‚¹è¿é€šæ€§
    if ping -c 1 -W 1 $node &> /dev/null; then
        # è·å–èŠ‚ç‚¹æŒ‡æ ‡
        NODE_CPU=$(ssh $node "top -bn1 | grep 'Cpu(s)' | awk '{print 100 - $8}' | sed 's/%id,//'")
        NODE_MEM=$(ssh $node "free -m | awk 'NR==2{printf \"%.2f\", $3*100/$2}'")
        NODE_LOAD=$(ssh $node "uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | sed 's/,//'")

        echo "  {\"node\": \"$node\", \"status\": \"online\", \"cpu\": $NODE_CPU, \"memory\": $NODE_MEM, \"load\": $NODE_LOAD}" >> $STATUS_FILE
    else
        echo "  {\"node\": \"$node\", \"status\": \"offline\"}" >> $STATUS_FILE
    fi
done

echo ']}' >> $STATUS_FILE
```

**é›†ç¾¤å¥åº·åº¦è®¡ç®—ï¼š**

```python
#!/usr/bin/env python3
# /opt/monitoring/cluster_health.py

import json
import statistics
from datetime import datetime

def calculate_cluster_health():
    """è®¡ç®—é›†ç¾¤å¥åº·åº¦"""

    with open('/var/log/cluster_status.json', 'r') as f:
        data = json.load(f)

    nodes = data['nodes']
    online_nodes = [n for n in nodes if n['status'] == 'online']
    offline_count = len(nodes) - len(online_nodes)

    if not online_nodes:
        return {
            'health_score': 0,
            'status': 'CRITICAL',
            'message': 'No nodes online',
            'offline_count': offline_count
        }

    # è®¡ç®—å¹³å‡CPUä½¿ç”¨ç‡
    avg_cpu = statistics.mean([n['cpu'] for n in online_nodes])
    max_cpu = max([n['cpu'] for n in online_nodes])

    # è®¡ç®—å¹³å‡å†…å­˜ä½¿ç”¨ç‡
    avg_mem = statistics.mean([n['memory'] for n in online_nodes])
    max_mem = max([n['memory'] for n in online_nodes])

    # è®¡ç®—å¹³å‡è´Ÿè½½
    avg_load = statistics.mean([n['load'] for n in online_nodes])
    max_load = max([n['load'] for n in online_nodes])

    # å¥åº·åº¦è®¡ç®—
    cpu_score = max(0, 100 - max_cpu)
    mem_score = max(0, 100 - max_mem)
    load_score = max(0, 100 - (max_load * 10))  # è´Ÿè½½æƒé‡è¾ƒä½
    availability_score = (len(online_nodes) / len(nodes)) * 100

    health_score = statistics.mean([cpu_score, mem_score, load_score, availability_score])

    # ç¡®å®šçŠ¶æ€
    if health_score >= 80:
        status = 'GOOD'
    elif health_score >= 60:
        status = 'WARNING'
    else:
        status = 'CRITICAL'

    return {
        'health_score': round(health_score, 2),
        'status': status,
        'avg_cpu': round(avg_cpu, 2),
        'max_cpu': round(max_cpu, 2),
        'avg_memory': round(avg_mem, 2),
        'max_memory': round(max_mem, 2),
        'avg_load': round(avg_load, 2),
        'max_load': round(max_load, 2),
        'online_nodes': len(online_nodes),
        'total_nodes': len(nodes),
        'offline_count': offline_count,
        'timestamp': data['timestamp']
    }

if __name__ == '__main__':
    health = calculate_cluster_health()
    print(json.dumps(health, indent=2))
```

## ğŸ› ï¸ å®è·µæ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šåŸºäºPrometheusçš„HPCç›‘æ§

**éƒ¨ç½²Prometheusç›‘æ§æ ˆï¼š**

```yaml
# docker-compose.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana

  node-exporter:
    image: prom/node-exporter:latest
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'

volumes:
  prometheus_data:
  grafana_data:
```

**Prometheusé…ç½®ï¼š**

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'compute-nodes'
    static_configs:
      - targets:
          - 'compute-node-01:9100'
          - 'compute-node-02:9100'
          - 'compute-node-03:9100'
```

### æ¡ˆä¾‹2ï¼šäº‘åŸç”Ÿæ—¥å¿—ç›‘æ§ (Grafana Loki)

Loki æ˜¯ Grafana Labs å¼€å‘çš„æ°´å¹³å¯æ‰©å±•ã€é«˜å¯ç”¨ã€å¤šç§Ÿæˆ·çš„æ—¥å¿—èšåˆç³»ç»Ÿï¼Œä¸“ä¸ºæ•ˆç‡è€Œè®¾è®¡ã€‚å®ƒä¸ç´¢å¼•æ—¥å¿—å†…å®¹ï¼Œåªç´¢å¼•æ ‡ç­¾ï¼Œéå¸¸é€‚åˆ HPC é«˜ååæ—¥å¿—ã€‚

**Loki æ ˆé…ç½® (Docker Compose)ï¼š**

```yaml
version: "3"
services:
  loki:
    image: grafana/loki:2.8.0
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml

  promtail:
    image: grafana/promtail:2.8.0
    volumes:
      - /var/log:/var/log
    command: -config.file=/etc/promtail/config.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
```

**Promtail é…ç½® (æ—¥å¿—é‡‡é›†)ï¼š**

```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
- job_name: system
  static_configs:
  - targets:
      - localhost
    labels:
      job: varlogs
      __path__: /var/log/*log
```

## ğŸ“š æœ€ä½³å®è·µ

### ç›‘æ§ç³»ç»Ÿè®¾è®¡åŸåˆ™

1. **åˆ†å±‚ç›‘æ§**ï¼šåŸºç¡€è®¾æ–½ â†’ ä¸­é—´ä»¶ â†’ åº”ç”¨å±‚
2. **æŒ‡æ ‡æ ‡å‡†åŒ–**ï¼šç»Ÿä¸€æŒ‡æ ‡å‘½åå’Œå•ä½
3. **å‘Šè­¦åˆ†çº§**ï¼šæ ¹æ®å½±å“èŒƒå›´è®¾ç½®ä¸åŒçº§åˆ«
4. **è‡ªåŠ¨åŒ–å¤„ç†**ï¼šè‡ªåŠ¨æ•…éšœè½¬ç§»å’Œæ¢å¤
5. **å†å²æ•°æ®ä¿ç•™**ï¼šé•¿æœŸæ€§èƒ½è¶‹åŠ¿åˆ†æ

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **é‡‡æ ·é¢‘ç‡**ï¼šæ ¹æ®éœ€æ±‚è°ƒæ•´ï¼Œé¿å…è¿‡åº¦ç›‘æ§
2. **æ•°æ®èšåˆ**ï¼šå¯¹å¤§é‡æ•°æ®è¿›è¡Œé¢„èšåˆ
3. **å­˜å‚¨ä¼˜åŒ–**ï¼šä½¿ç”¨åˆé€‚çš„æ•°æ®ä¿ç•™ç­–ç•¥
4. **æŸ¥è¯¢ä¼˜åŒ–**ï¼šé¿å…å¤æ‚çš„å®æ—¶æŸ¥è¯¢

### æ•…éšœå¤„ç†æµç¨‹

1. **å‘Šè­¦ç¡®è®¤**ï¼šéªŒè¯å‘Šè­¦çœŸå®æ€§
2. **å½±å“è¯„ä¼°**ï¼šåˆ¤æ–­æ•…éšœå½±å“èŒƒå›´
3. **å¿«é€Ÿæ¢å¤**ï¼šå®æ–½åº”æ€¥å¤„ç†æªæ–½
4. **æ ¹æœ¬è§£å†³**ï¼šåˆ†ææ ¹æœ¬åŸå› å¹¶ä¿®å¤
5. **ç»éªŒæ€»ç»“**ï¼šæ›´æ–°ç›‘æ§ç­–ç•¥å’Œæ–‡æ¡£

## ğŸ“ æœ¬ç« æ€»ç»“

ç³»ç»Ÿç›‘æ§æ˜¯HPCè¿ç»´çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œé€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- âœ… éƒ¨ç½²å’Œé…ç½®ä¸»æµç›‘æ§å·¥å…·ï¼ˆNagiosã€Zabbixï¼‰
- âœ… æ”¶é›†å’Œåˆ†æå…³é”®æ€§èƒ½æŒ‡æ ‡
- âœ… é…ç½®æœ‰æ•ˆçš„å‘Šè­¦ç­–ç•¥
- âœ… æ„å»ºç›´è§‚çš„å¯è§†åŒ–ç›‘æ§é¢æ¿
- âœ… è®¾è®¡é›†ç¾¤çº§ç›‘æ§ä½“ç³»

ç›‘æ§ç³»ç»Ÿçš„å»ºè®¾æ˜¯ä¸€ä¸ªæŒç»­ä¼˜åŒ–çš„è¿‡ç¨‹ï¼Œéœ€è¦æ ¹æ®å®é™…è¿è¡Œæƒ…å†µä¸æ–­è°ƒæ•´å’Œå®Œå–„ã€‚

## ğŸ“ ç»ƒä¹ é¢˜

1. **å®è·µé¢˜**ï¼šåœ¨ä½ çš„ç¯å¢ƒä¸­éƒ¨ç½²Nagiosç›‘æ§ç³»ç»Ÿ
2. **é…ç½®é¢˜**ï¼šä¸ºè®¡ç®—èŠ‚ç‚¹é…ç½®CPUå’Œå†…å­˜å‘Šè­¦
3. **åˆ†æé¢˜**ï¼šåˆ†æä¸€å‘¨çš„ç›‘æ§æ•°æ®ï¼Œè¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
4. **è®¾è®¡é¢˜**ï¼šè®¾è®¡ä¸€ä¸ªåŒ…å«20ä¸ªèŠ‚ç‚¹çš„é›†ç¾¤ç›‘æ§æ–¹æ¡ˆ

## ğŸ”— å‚è€ƒèµ„æº

- [Nagioså®˜æ–¹æ–‡æ¡£](https://www.nagios.org/documentation/)
- [Zabbixå®˜æ–¹æ–‡æ¡£](https://www.zabbix.com/documentation)
- [Prometheuså®˜æ–¹æ–‡æ¡£](https://prometheus.io/docs/)
- [Grafanaå®˜æ–¹æ–‡æ¡£](https://grafana.com/docs/)